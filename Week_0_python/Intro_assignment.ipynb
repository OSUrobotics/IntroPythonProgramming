{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"Intro_assignment.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "This assignment serves several purposes:\n",
    "- Python refresher (tutorials a-g) in case it's been awhile\n",
    "- An introduction to the autograder/submitting to gradescope\n",
    "- An introduction to Jupyter Notebooks and the format of the assignments\n",
    "\n",
    "For each assignment the top of the Jupyter Notebook will have additional links, either to recommended tutorials and/or slides that further describe the assignment. These slides will have a mix of helpful hints, guidelines, and what the expected outcomes should be (particularly for plots). There is a good chance that any question you have will have an answer in those slides, so check them first. \n",
    "\n",
    "## Jupyter notebook structure\n",
    "\n",
    "For each question there's an autograder check; almost always there will be a cell that has the exact same code as the autograder check so you can see what it is. If you pass the autograder checks here, then (probably) you will pass the Gradescope autograder. **You should always check the result of the Gradescope autograder and make sure you got full credit.** If you don't, the reason you didn't is (probably) here: https://docs.google.com/presentation/d/1tYa5oycUiG4YhXUq5vHvPOpWJ4k_xUPp2rUNIL7Q9RI/edit?usp=sharing. There are additional instructions at the end of each Jupyter Notebook that you should read before handing in.\n",
    "\n",
    "There's usually a lot of supplied code/instructions. Anything you're suppose to change is labeled with \"GUIDE\". When in doubt, look to see what the autograder is checking for.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing the imports for you\n",
    "# Note, if this fails try running a_start_here_libraries.ipynb first\n",
    "#  If you've done that, then make sure that the kernel you've selected for both is the same\n",
    "#  If that doesn't work, find a TA.\n",
    "import numpy as np\n",
    "import json as json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Tutorials A and B: strings\n",
    "\n",
    "These are minor variations on the practice problems in *c_practice_strings.ipynb*. If you can't answer them, go back to the **a** and **b** tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m data_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# This is what the autograder will check\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m data_file_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# GUIDE: Create a string from the following variables\n",
    "\n",
    "name_of_file = \"data\"\n",
    "file_number = 1\n",
    "file_ending = \"csv\"\n",
    "\n",
    "\n",
    "# GUIDE: replace ... with string creation\n",
    "data_file_name = ...\n",
    "\n",
    "print(f\"{data_file_name}, {da}\")\n",
    "# This is what the autograder will check\n",
    "assert data_file_name == \"data1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "file_name = \"fname.txt\"\n",
    "which_one = 1\n",
    "\n",
    "# GUIDE: Change this so that new_file_name is \"fname1.csv\" by EDITING file_name and using which_one - don't just type the new name in.\n",
    "#  I.e., it should still work even if we change file_name to be something else and which_one to be a different number\n",
    "# HINT: take fname.txt apart by using split, with . as the split\n",
    "#  Build the new name by taking the first part of the split, converting which_one to a string, then gluing it all together with .csv\n",
    "\n",
    "# Feel free to write more code and do it in pieces - i.e., you might start with \n",
    "#     fname_split = file_name.split(\".\")\n",
    "# and print out fname_split... OR try clicking on the Variables button above, next to Clear All Outputs\n",
    "\n",
    "# HINT 2: To get the first element out of a list, remember python starts at 0. So try printing fname_split[0]\n",
    "\n",
    "\n",
    "# GUIDE: Build new_file_name. You may write as many lines of code as you want - you do not have to do this in one line.\n",
    "#   Do NOT just put the desired string in. Actually build it from the variables fname and which_one\n",
    "new_file_name = file_name\n",
    "\n",
    "# This is what the autograder will check\n",
    "assert new_file_name == \"fname1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>Strings</pre> results:</strong></p><p><strong><pre style='display: inline;'>Strings - 1</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Trying:\n",
       "        assert data_file_name == 'data1.csv'\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in Strings 0\n",
       "    Failed example:\n",
       "        assert data_file_name == 'data1.csv'\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/opt/anaconda3/lib/python3.12/doctest.py\", line 1368, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest Strings 0[0]>\", line 1, in <module>\n",
       "            assert data_file_name == 'data1.csv'\n",
       "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "        AssertionError\n",
       "</pre><p><strong><pre style='display: inline;'>Strings - 2</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Trying:\n",
       "        assert new_file_name == 'fname1.csv'\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in Strings 1\n",
       "    Failed example:\n",
       "        assert new_file_name == 'fname1.csv'\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/opt/anaconda3/lib/python3.12/doctest.py\", line 1368, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest Strings 1[0]>\", line 1, in <module>\n",
       "            assert new_file_name == 'fname1.csv'\n",
       "                   ^^^^^^^^^^^^^\n",
       "        NameError: name 'new_file_name' is not defined. Did you mean: 'data_file_name'?\n",
       "</pre>"
      ],
      "text/plain": [
       "Strings results:\n",
       "    Strings - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert data_file_name == 'data1.csv'\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in Strings 0\n",
       "        Failed example:\n",
       "            assert data_file_name == 'data1.csv'\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/anaconda3/lib/python3.12/doctest.py\", line 1368, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest Strings 0[0]>\", line 1, in <module>\n",
       "                assert data_file_name == 'data1.csv'\n",
       "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "            AssertionError\n",
       "\n",
       "    Strings - 2 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert new_file_name == 'fname1.csv'\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in Strings 1\n",
       "        Failed example:\n",
       "            assert new_file_name == 'fname1.csv'\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/anaconda3/lib/python3.12/doctest.py\", line 1368, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest Strings 1[0]>\", line 1, in <module>\n",
       "                assert new_file_name == 'fname1.csv'\n",
       "                       ^^^^^^^^^^^^^\n",
       "            NameError: name 'new_file_name' is not defined. Did you mean: 'data_file_name'?"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"Strings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Tutorial D: Lists\n",
    "\n",
    "These are minor variations on the practice problems in *e_practice_lists.ipynb*. If you can't answer them, go back to the **d** tutorial. \n",
    "\n",
    "If you have never used Python lists before, there are a couple on-line tutorials recommended at the top of *d_tutorial_list.ipynb*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# GUIDE Create a list of filenames, fname1.csv, fname2.csv, ... fname3.csv\n",
    "# You must use the variables listed below to set the name of the file, the number of file names to create, and the file ending\n",
    "\n",
    "file_name = \"fname\"\n",
    "file_ending = \".csv\"\n",
    "\n",
    "n_to_do = 3\n",
    "\n",
    "my_list_of_file_names = []\n",
    "\n",
    "# Do NOT re-use the variable name new_file_name here, btw. Pick a different name\n",
    "\n",
    "# HINT 1: You'll want the function range() for the for loop\n",
    "# HINT 2: You can either have range go from 1 to 3 OR have range go from 0 to 2 and just add one when you create the string\n",
    "# HINT 3: I recommend building the string and then appending it (use two lines) rather than doing it in one fell swoop \n",
    "#    (easier to debug)\n",
    "...\n",
    "\n",
    "# The autograder is going to check the following:\n",
    "#  That the list has n_to_do elements in it\n",
    "#  That the first element in the list is fname1.csv\n",
    "#  That the last element in the list is fname3.csv\n",
    "\n",
    "# GUIDE Write your own tests here using assert to check the above three things\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"Lists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Tutorials F and G: dictionaries\n",
    "\n",
    "These are minor variations on the practice problems in *g_practice_dictionary.ipynb*. If you can't answer them, go back to **f_tutorial_dictionary** tutorial (there's a link to an on-line tutorial in there that is also helpful)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# GUIDE: Create a dictionary that has 3 key-pairs in it\n",
    "#     key: \"name\", value \"Me\"\n",
    "#     key: \"age\", value 10\n",
    "#     key: \"grades\", value a list with three elements,  \"A\", \"A\", \"A\"\n",
    "# NOTE: The autograder will not pass until you do both this bit and the next\n",
    "\n",
    "\n",
    "# GUIDE: Create my_simple_dict\n",
    "#   You can either create the dictionary all at once or just add each key-value pair in turn\n",
    "my_simple_dict = {}\n",
    "\n",
    "# Remember that string comparison is case-sensitive\n",
    "assert my_simple_dict[\"name\"] == \"Me\"\n",
    "assert my_simple_dict[\"age\"] == 10\n",
    "assert len(my_simple_dict[\"grades\"]) == 3\n",
    "for grade in my_simple_dict[\"grades\"]:\n",
    "    assert grade == \"A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# GUIDE: \n",
    "#    - Add one to the age\n",
    "#    - Add another \"A\" grade to the list\n",
    "# Do these by editing the existing key-value pairs\n",
    "\n",
    "# replace the ... with your code\n",
    "...\n",
    "\n",
    "assert my_simple_dict[\"age\"] == 11\n",
    "assert len(my_simple_dict[\"grades\"]) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"Dictionaries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Hours and collaborators\n",
    "Required for every assignment - fill out before you hand-in.\n",
    "\n",
    "Listing names and websites helps you to document who you worked with and what internet help you received in the case of any plagiarism issues. You should list names of anyone (in class or not) who has substantially helped you with an assignment - or anyone you have *helped*. You do not need to list TAs.\n",
    "\n",
    "Listing hours helps us track if the assignments are too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# List of names (creates a set)\n",
    "worked_with_names = {\"not filled out\"}\n",
    "# List of URLS W26 (creates a set)\n",
    "websites = {\"not filled out\"}\n",
    "# Approximate number of hours, including lab/in-class time\n",
    "hours = -1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"hours_collaborators\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To submit\n",
    "\n",
    "Read me!!! This last cell will always have hand-in instructions. They're pretty boring (most of the time) but around week 5 you'll need to do more than just hand in this .ipynb. It is your responsibility to check if the Gradescope autograder ran correctly.\n",
    "\n",
    "- Hit clear all outputs (this removes all the outputs)\n",
    "- Hit Restart (say yes when it asks if it's ok to blow everything away)\n",
    "- Hit 'Run All' to make sure that your code executes from top to bottom from scratch. \n",
    "\n",
    "If you hand in a file without doing this we will deduct points (the little numbers to the left of the first cell should be 1 and all cells executed)\n",
    "\n",
    "- Make sure the file has saved (there is no little black dot to the right of the file name in the top bar)\n",
    "- Submit this .ipynb file to Gradescope. Do NOT submit the tutorial files - Gradescope expects 1, and only 1, file with an .ipynb extension.\n",
    "- Go get a cup of coffee (or tea or whatever). Come back and check that your autograder score is 5/5\n",
    "\n",
    "If the Gradescope autograder fails (you did not get 5/5 and you know everything worked), please check here first for common reasons for it to fail\n",
    "    https://docs.google.com/presentation/d/1tYa5oycUiG4YhXUq5vHvPOpWJ4k_xUPp2rUNIL7Q9RI/edit?usp=sharing\n",
    "\n",
    "Make sure you remove all the print statements you put in that print out lots of stuff. You will get deducted for this, too, if the TAs have to wade through pages of print out stuff. One or two lines is ok."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "Dictionaries": {
     "name": "Dictionaries",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert my_simple_dict['name'] == 'Me'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert my_simple_dict['age'] == 11\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert len(my_simple_dict['grades']) == 4\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> for grade in my_simple_dict['grades']:\n...     assert grade == 'A'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Lists": {
     "name": "Lists",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(my_list_of_file_names) == n_to_do\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert my_list_of_file_names[0] == 'fname1.csv'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert my_list_of_file_names[-1] == 'fname' + str(n_to_do) + '.csv'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Strings": {
     "name": "Strings",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert data_file_name == 'data1.csv'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert new_file_name == 'fname1.csv'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "hours_collaborators": {
     "name": "hours_collaborators",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not 'not filled out' in worked_with_names\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert not 'not filled out' in websites\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert hours > 0\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
