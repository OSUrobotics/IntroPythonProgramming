{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"Lab_1_arrays_and_dictionaries.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Statistical analysis of data using numpy\n",
    "\n",
    "Read the Lab slides:  https://docs.google.com/presentation/d/1lVYGqoStt0ZdnRAYMfF9Km6f0NgMNkuYgINsRhXASwI/edit?usp=sharing before starting this problem\n",
    "\n",
    "Additional resources: What you're doing laid out visually, see miro https://miro.com/app/board/uXjVOWs8R4Y=/?share_link_id=567398312390 Lab 1: frame, mapping between task and code and the Lab slides\n",
    "\n",
    "Motivation: Whether you're in engineering or business or health care - almost any field nowadays - you need to be able to work with data. Just about every thing that touches a computer now has the ability to store data. Most of this data will be numbers, but sometimes it will be qualitative data (think 3 people like this, 10 people don't).\n",
    "\n",
    "You can do a lot of data analysis with spreadsheets, but at some point it's almost always easier to write some code to either *put* data into a spread sheet in a form that's useful, to *pull* specific data from one (or more) spreadsheets, or to automate some processes (like creating six custom plots from this month's data showing price trends). Being able to write a bit of code to clean up or re-purpose data is really useful, and not too difficult.\n",
    "\n",
    "- Lab week 1: Read in data, re-arrange it, and use it to do (text-based) statistical analysis\n",
    "- Lab week 2: Same thing again, but this time with functions so you can re-use code\n",
    "- Lab week 3: Plot the data you worked with in labs week 1  & 2\n",
    "- Homework weeks 1, 2 & 3: \n",
    "-- Make the code more general, so you can look at different data channels\n",
    "-- Make nicer plots\n",
    "\n",
    "Some notes on the data you'll be working with. This is real data captured by a robotic hand designed to pick fruit. The hand is instrumented with a couple sensors (IMUs in each of the three fingers, force and torque information at the wrist and information from the motors driving the three fingers). Each of these sensors outputs a data stream, which we've stored in a csv file. \n",
    "\n",
    "Big picture: We want to know if we can detect if the apple was picked or not from the sensor data. Each row of the Data/proxy_pick_data.csv file is data from a single picking trial. Each group of n columns represents one time step. We want to plot/analyze data from different data channels to see if there is a difference between the successful and unsuccessful picks.\n",
    "\n",
    "For this lab the goal is to pull out one data channel (the wrist torque sensor) and print out statistics for failed versus successful picks. Yes, you could do all of this by manually going into the spreadsheet, sorting\n",
    "columns, and setting up some spreadsheet formulas. That works for one data channel... but what if you want to do a different one? Or the data file format changes because someone added another sensor? Or you're asked to throw out the biggest n samples?\n",
    "\n",
    "Yes, this is going to be frustrating/seem like a lot of work for nothing the first time you do it. The point is not\n",
    "to do this particularly task, but to learn how to access data in dictionaries, lists, and numpy arrays to \"pull out\"\n",
    "data that you're interested in. Yes, I could just tell you to use numpy slicing to pull out every 15th column,\n",
    "starting with the 3rd column, and sort by the last column, but where would the fun be in that?\n",
    "\n",
    "Note: Next week we'll take what we write here and put it into functions.\n",
    "\n",
    "Note 2: The data structure is very similar to the one you used in the lecture activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safety check - if you did not install json correctly this should do it for you\n",
    "#  It should spit out a bunch of \"requirement already satisfied\" messages\n",
    "import sys\n",
    "!{sys.executable} -m pip install json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries that we need to import - numpy and json (for loading the description file)\n",
    "import numpy as np\n",
    "import json as json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in data\n",
    "TODO First step, read in the data from **Data/proxy_pick_data.csv** and put it in a numpy array pick_data. Don't forget to set the delimiter.\n",
    " - to find out more about the numpy method **loadtxt**, Google *numpy loadtxt* \n",
    " - there is also an example in a_tutorial_numpy.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXAMPLE CODE\n",
    "# The example code for the data load is in a_tutorial_numpy.ipynb - search for loadtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "# TODO - put the code to load the data here.\n",
    "pick_data = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXAMPLE CODE\n",
    "#  See the \"What are the dimensions of the data?\" in lec_act_1_data_structures.ipynb\n",
    "\n",
    "# Make the same data set we used in lec_act_1_data_structures.ipynb - just a bit more concisely\n",
    "# Make space\n",
    "my_test_data = np.zeros((5, 3 * 10 + 1))\n",
    "# Last column\n",
    "my_test_data[0::2, -1] = 1\n",
    "\n",
    "# x-data\n",
    "x_data_for_one_row = np.linspace(start=0, stop=1.0, num=10)\n",
    "for r in range(0, my_test_data.shape[0]):\n",
    "    # loop through each row r\n",
    "    # Fill in column 0 to one before the end (don't overwrite the good/bad), skipping every 3\n",
    "    my_test_data[r, 0:-2:3] = x_data_for_one_row\n",
    "\n",
    "# y-data\n",
    "my_test_data[:, 1::3] = np.random.uniform(-1.0, 0.0, size=(5, 10))\n",
    "\n",
    "# z-data\n",
    "my_test_data[:, 2::3] = np.random.uniform(10.0, 20.0, size=(5, 10))\n",
    "\n",
    "# Number of rows is in shape[0], columns in shape[1]\n",
    "num_rows = my_test_data.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO \n",
    "#  - set the n_picks variable. Do NOT just put in a number - use the variable pick_data to calculate this\n",
    "#  - change the print line to print out the number of picks\n",
    "n_picks = ...\n",
    "print(f\"Number of picks: {}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXAMPLE CODE\n",
    "# Remember you want all of the rows - that's what the : is for\n",
    "# To get just the last column, use -1\n",
    "get_last_column = my_test_data[:, -1]\n",
    "print(f\"Last column: {get_last_column}\")\n",
    "\n",
    "# An example of count_nonzero\n",
    "#  Make a numpy array with 10 elements, all set to 1\n",
    "an_array_of_ten_ones = np.ones((10))\n",
    "# Count the number of ones\n",
    "print(f\"How many ones? {np.count_nonzero(an_array_of_ten_ones == 1.0)}\")\n",
    "\n",
    "# Sum will return a double, not an integer. Use int() to change a double to an integer\n",
    "#   You can tell it's a double by the 10.0 on the print out\n",
    "print(f\"Sum of array as double {np.sum(an_array_of_ten_ones)} and integer {int(np.sum(an_array_of_ten_ones))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO - set the variable n_successful and print it out. Do NOT just put in a number - use the variable pick_data\n",
    "#   Calculating the number of successful picks: The number of values in the last column that are 1 (use np.count_nonzero)\n",
    "\n",
    "n_successful = ...\n",
    "print(f\"Number of successful picks: {}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"count_rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### JSON, lists, and dictionaries: Getting information from a file\n",
    "The format of the spreadsheet data is given in Data/proxy_data_description.json. \n",
    "\n",
    "TODO: Open up the file using VSCode (just click on Data then click on the file) and look through it to see if it makes sense. Also open up proxy_pick_data.csv the same way and make sure you understand the data format (see slides).\n",
    "\n",
    "- Step 1 (this problem): Figure out how to get the \"Data channels\" list out of pick_data_description\n",
    "Note: **pick_data_description** is a dictionary.\n",
    "\n",
    "- Step 2 (this problem): Find the size of the list\n",
    "\n",
    "- Step 3 (next problem): Find the total number of dimensions of the data and the number of time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# This reads in the json data\n",
    "# Try-except is just a fancy if-then statement that says if the file is not found, spit out the print statement (instead of\n",
    "#  the usual incomprehensible python error messages)\n",
    "try:\n",
    "    with open(\"Data/proxy_data_description.json\", \"r\") as fp:\n",
    "        pick_data_description = json.load(fp)\n",
    "except FileNotFoundError:\n",
    "    print(f\"The file was not found; check that the data directory is in the current one and the file is in that directory\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### How many sensor data channels?\n",
    "\n",
    "TODO:  Figure out how many different data channels there are, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXAMPLE CODE, step 1\n",
    "\n",
    "my_test_dictionary = {\"Key 1 name\": \"Name\",\n",
    "                      \"Key 2 data list\": [1, 2, 3]}\n",
    "\n",
    "# Get list out of the dictionary\n",
    "list_from_dictionary = my_test_dictionary[\"Key 2 data list\"]\n",
    "print(f\"List {list_from_dictionary}\")\n",
    "\n",
    "# Sum up all of the elements in the list\n",
    "sum_elems = 0\n",
    "for item in list_from_dictionary:\n",
    "    sum_elems += item\n",
    "                    \n",
    "print(f\"Sum of elements in list is: 1+2+3 = {sum_elems}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO - use the key \"Data channels\" to get out the list of data channels from pick_data_description\n",
    "data_channels = ...\n",
    "# How many elements does the list have in it?\n",
    "number_of_data_channels = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"read_json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Loop over the data channels and add up the total number of dimensions\n",
    "\n",
    "TODO: Turn this pseudo code into real code\n",
    "\n",
    "- total number of channels = 0\n",
    "\n",
    "- for each channel in data_channels list\n",
    "   - add in the number of dimensions (key is \"dimensions\")\n",
    "\n",
    "Check in **proxy_pick_data.csv** that the number of dimensions you found was where the data repeats itself\n",
    "\n",
    "Stuck? Try printing out **pick_data_description** and match that to what you see in the json file. Try getting the first element out (is it a list or a dictionary? How do you access a list or a dictionary element?) and printing it. Repeat until you're sure you know how to get the number of dimensions of the first channel.\n",
    "\n",
    "Now put it in a **for** loop, looping over the list. Print out each element in the list in the **for** loop.\n",
    "\n",
    "Now change the print statement to just print out the **dimensions** value.\n",
    "\n",
    "Now you can do the sum - you can use **x = x + v **.  OR ** x += v**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_total_dims = 0\n",
    "# TODO 1: turn this pseudo code into real code. \n",
    "#. for each item in data channels\n",
    "#.    Get the number of dimmensions in that element and add it to n_total_dims\n",
    "#.  Note that each item in data channels is a dictionary - so you'll have to get the number out of the dictionary\n",
    "#\n",
    "# TODO: Fill out the print statement with the number of items in the data channels list, and \n",
    "# the total number of dimensions you calculated\n",
    "print(f\"Number of data channels items in list: {}, total summed number of dimensions: {n_total_dims}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXAMPLE CODE\n",
    "num_channels_test_data = 3  # x, y, z - we made the data with three channels\n",
    "\n",
    "# Get all of the test data EXCEPT the last column\n",
    "#  The first : is all the rows, the :-1 is all but the last\n",
    "just_xyz_test_data = my_test_data[:, :-1]\n",
    "\n",
    "# Get the last column (successful/not)\n",
    "#   The first : is all the rows, the -1 is JUST the last row\n",
    "just_successful_test_data = my_test_data[:, -1]\n",
    "\n",
    "# TODO: Look at both of the above variables in the variable window\n",
    "\n",
    "# This is the shape of the original data, minus one column\n",
    "expected_shape = (my_test_data.shape[0], my_test_data.shape[1]-1)\n",
    "# This one should be that size\n",
    "assert(just_xyz_test_data.shape == expected_shape)\n",
    "\n",
    "# And this one is number of rows * 1 size\n",
    "assert(just_successful_test_data.size == 5)\n",
    "\n",
    "# Now do the actual divide to get the number of time steps\n",
    "n_time_steps_test_data = just_xyz_test_data.shape[1] // num_channels_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Split pick_data into two parts - the actual channel data and the last column\n",
    "pick_channel_data = ...\n",
    "pick_successful = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Calculate number of time steps\n",
    "n_time_steps = ...\n",
    "print(f\"Number of time steps: {n_time_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"number_dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data slicing to get out the Wrist torque data\n",
    "\n",
    "Practice slicing - pull out the X, Y, Z data for the Wrist torque channel for all picks\n",
    "\n",
    "You are free to use the fact that the name of the data channel you want is Wrist torque, but you should get the actual offset index value from the dictionary, not just do index_wrist_torque_start_index = 3 (suppose someone changed the order of the data...).\n",
    "\n",
    "There are several ways to do this; the simplest is to loop through all of the data channels looking for the one\n",
    "that is called \"Wrist torque\" and then set the index offset value from that. It would be a good idea to check that you actually found the right starting index by looking at the .json file. Don't forget that numpy indexes from 0.\n",
    "\n",
    "Note: Use ==, not **is**, for the string comparison. \n",
    "\n",
    "We'll do this in two parts (second part is next question): \n",
    "\n",
    "- TODO: Get the start index from the dictionary\n",
    "- TODO: Slice pick_channel_data to get out just the Wrist Torque x,y,z data\n",
    "- TODO: Optional: Reshape this slice to be n_picks X xyz X time data (a 3 dimensional matrix of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXAMPLE CODE\n",
    "\n",
    "# These are examples of how to get data out of the pick_data_description data structure\n",
    "#   Reminder that you already stored the list \"Data channels\" in the variable data_channels\n",
    "\n",
    "# Grab the second dictionary in the list of dictionaries\n",
    "get_second_dictionary_in_list = data_channels[1]\n",
    "\n",
    "# Look at proxy_data_description.json - this is one if the dictionaries in that file \n",
    "print(f\"What is in one dictionary entry:\\n {get_second_dictionary_in_list}\")\n",
    "\n",
    "# Using the \"name\" key to get the name stored in this dictionary\n",
    "name_in_dictionary = get_second_dictionary_in_list[\"name\"]\n",
    "\n",
    "# Using the \"start_index\" key to get the starting index\n",
    "start_index_in_dictionary = get_second_dictionary_in_list[\"index_offset\"]\n",
    "\n",
    "print(f\"Channel {name_in_dictionary} starts at {start_index_in_dictionary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is the name we're searching for. Using a variable so that we can change from Wrist torque to something else later\n",
    "\n",
    "channel_name = \"Wrist torque\"\n",
    "index_wrist_torque_offset = -1  #  Set it to a value that is NOT a valid index\n",
    "# TODO: Turn this pseudo code into real code\n",
    "# for each channel in data channels\n",
    "#     if this channel's name is the one I'm looking for    \n",
    "#.        Set index_wrist_torque_offset to that channel's start index\n",
    "\n",
    "\n",
    "# Check that you actually set the value somewhere in the loop - this is \"defensive coding\"\n",
    "if index_wrist_torque_offset == -1:\n",
    "    print(f\"Error: No channel {channel_name} found\")\n",
    "    \n",
    "print(f\"Offset for wrist torque: {index_wrist_torque_offset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"channel_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 2 - Now use slicing to get out all of the wrist torque data\n",
    "\n",
    "The goal is to slice the data to get out a numpy array that is n_picks by n_time_steps*3. The 3 is because we have x, y, and z data. This is a bit like the way **my_test_data** was created (create an empty array, set the x, then the y, then the z data)\n",
    "\n",
    "- First, use the slice operator selecting all rows and columns, **data[:, :]**\n",
    "- Now change the column slice from all columns (:) to starting at the offset value you just calculated.\n",
    "- Now change the slice to take a step/stride of **n_total_dims** instead of 1\n",
    "- Reminder: slicing is  **start:end:step**\n",
    "\n",
    "Note: You don't need to put an end value in - just leave it blank if you want to go all the way to the end\n",
    "\n",
    "Remember: The data is in **pick_channel_data**, not **pick_data_description**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We know that this channel's data has x,y,z values (3 dimens). Use a variable instead of just the number 3\n",
    "#  in case we want to change it later\n",
    "n_dims_for_wrist_torque_data = 3\n",
    "# Create space for the data\n",
    "wrist_torque_data = np.zeros((n_picks, n_time_steps * n_dims_for_wrist_torque_data))\n",
    "\n",
    "#\n",
    "\n",
    "# TODO 1 Fix this to copy the x data into wrist_torque_data\n",
    "#  On the left-hand side, the columns should start at zero and increment by 3 (n_dims_for_wrist_torque_data)\n",
    "#  On the right-hand side, the columns should start at index_wrist_torque_offset and increment by n_total_dims\n",
    "wrist_torque_data[:, :] = pick_channel_data[:, :]\n",
    "\n",
    "# TODO 2 Copy the line above and change it to copy the y data. Hint: The increments are the same, but the starting\n",
    "#  index should be 1 more than the x starting index (on both the left and the right)\n",
    "\n",
    "# TODO 3 Now do the same for the z data\n",
    "#  Option 1: Do the same thing you did for y, but add 2 instead of 1\n",
    "#  Option 2: Edit your y code to do all three (x,y, and z) with a for loop\n",
    "#    The for loop should go from 0 to 2   for i in range(0, 3):\n",
    "#    Replace the +1 with +i \n",
    "\n",
    "# Cleaning up - if you used numbers for the start index and/or the slice spacing, replace those with index_wrist_torque_offset and\n",
    "#  n_dims_for_this_channel\n",
    "\n",
    "print(f\"Shape of wrist_torque_data is {wrist_torque_data.shape}, should be 660 X 120\")\n",
    "print(f\"  120 is 40 (number of time steps) * 3 (x,y,z)\")\n",
    "print(f\"First row, first column value {wrist_torque_data[0, 0]:0.2f}, should be -0.27\")\n",
    "print(f\"First row, last column value {wrist_torque_data[0, -1]:0.2f}, should be -0.08\")\n",
    "print(f\"Last row, first column value {wrist_torque_data[-1, 0]:0.2f}, should be -0.35\")\n",
    "print(f\"Last row, last column value {wrist_torque_data[-1, -1]:0.2f}, should be -0.05\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"slicing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Min/max/Mean/SD of z value\n",
    "\n",
    "Now that the wrist torque data is nicely separated out, find the min, max, mean and standard deviation of each of the x, y, and z channels. Put the result into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXAMPLE CODE\n",
    "# Get the min/max of the x values of the test code (should be 0 and 1) and store it in a dictionary\n",
    "\n",
    "# Since we have x,y, and z, we'll want a list to store the stats for each dimension\n",
    "my_list_of_stats = []\n",
    "\n",
    "# Since we need to do both min and max, create a variable that has the x slice\n",
    "#    The : says all of the rows, start at 0 and skip every 3rd\n",
    "x_slice = my_test_data[:, 0::3]\n",
    "\n",
    "# Put the results of min/max in a dictionary\n",
    "my_dict = {\"Min\" : np.min(x_slice),\n",
    "           \"Max\" : np.max(x_slice)}\n",
    "\n",
    "# Put the dictionary with the x min and max into the list\n",
    "my_list_of_stats.append(my_dict)\n",
    "\n",
    "print(f\"Stats {my_list_of_stats}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SCRATCH CELL\n",
    "# Try editing the above code to do the y and z channels as well - the result should be a list with three elements\n",
    "#  Option 1: Copy the code (from x_slice through the append ) and then change 0 to 1 to do the y channel.\n",
    "#  Option 2: Use a for loop over i=0,1,2 and change the 0 to an i\n",
    "#    Change the variable name from x_slice to something like cur_slice, since it will be the x slice, then the y, then the z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wrist_torque_stats_list = []\n",
    "\n",
    "# TODO For each of the x,y, and z data channels, calculate the min, max, mean and standard deviation. \n",
    "#   Store the values in a dictionary with the keys \"Min\", \"Max\", \"Mean\", and \"SD\"\n",
    "#   Put the dictionaries into the wrist_torque_stats_list list\n",
    "# Your output should look like Data/Lab1_check_results.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TEST CODE\n",
    "#   The correct answers are in Lab1_check_results.json. You can write test code here to check\n",
    "#   each value in turn, make sure the slicing is the correct size. This will not be graded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Boolean slicing to get successful versus unsuccessful picks out\n",
    "\n",
    "TODO: Calculate the min of the z values for the successful picks, and the min of the z values for the unsuccessful picks.\n",
    "\n",
    "The main difference between this problem and the previous one is that in this one you only use some of the rows (instead of all of them like the last problem). The column slice stays the same, but the row slice changes. We're going to use Boolean indexing to do this.\n",
    "\n",
    "Step 1: Create a boolean index that is True if the pick is successful, False if it is not\n",
    "Step 2: Use the boolean index to select the rows - only select rows where the index is True\n",
    "Step 3: Do the same thing again, but this time select rows that are False\n",
    "\n",
    "Remember that the successful/unsuccessful pick data was stored in **pick_successful**.\n",
    "\n",
    "Note: Use **== 1**, not **is 1** in the comparison\n",
    "\n",
    "Use **wrist_torque_data** for the data; remember that the z data starts at column 2, not 0, and the spacing is 3 (x,y,z). Use the variable **n_dims_for_wrist_torque_data** instead of the number 3 in your final version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXAMPLE CODE\n",
    "\n",
    "# This creates a boolean index that is True where the data is 1, False otherwise. (Look at it in the variable window\n",
    "#  and compare it to just_successful_test_data)\n",
    "b_is_true_and_false = just_successful_test_data == 1\n",
    "\n",
    "# This gets out just the rows that are true - look at it in the variable window\n",
    "my_test_data_only_good = my_test_data[b_is_true_and_false, :]\n",
    "\n",
    "# Now do the min over the z values\n",
    "xyz_skip = 3 \n",
    "z_start_offset = 2\n",
    "min_z = np.min(my_test_data_only_good[:, z_start_offset::xyz_skip])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Create a boolean array to pick out the successful rows\n",
    "bool_array_successful = ...\n",
    "\n",
    "# TODO: Now use that boolean array plus column slicing to calculate the min of the z values\n",
    "min_wrist_torque_successful_z = ...\n",
    "\n",
    "# TODO: Repeat for unsuccessful picks\n",
    "bool_array_unsuccessful = ...\n",
    "min_wrist_torque_unsuccessful_z = ...\n",
    "\n",
    "print(f\"Successful: Minimum value {min_wrist_torque_successful_z:0.4f} of wrist torque z channel\")\n",
    "print(f\"Unsuccessful: Minimum value {min_wrist_torque_unsuccessful_z:0.4f} of wrist torque z channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"boolean_slicing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Hours and collaborators\n",
    "Required for every assignment - fill out before you hand-in.\n",
    "\n",
    "Listing names and websites helps you to document who you worked with and what internet help you received in the case of any plagiarism issues. You should list names of anyone (in class or not) who has substantially helped you with an assignment - or anyone you have *helped*. You do not need to list TAs.\n",
    "\n",
    "Listing hours helps us track if the assignments are too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# List of names (creates a set)\n",
    "worked_with_names = {\"not filled out\"}\n",
    "# List of URLS TCW3 (creates a set)\n",
    "websites = {\"not filled out\"}\n",
    "# Approximate number of hours, including lab/in-class time\n",
    "hours = -1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"hours_collaborators\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Submit just the .ipynb file to Gradescope (Lab 1 Arrays and dictionaries). You do not need to submit the data files. Don't change the provided variable names or autograding will fail. Make sure to do a restart and run all before turning in. Look at the Gradescope grading rubric for code-quality checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False, run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "boolean_slicing": {
     "name": "boolean_slicing",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert(np.isclose(min_wrist_torque_unsuccessful_z, -0.62552044, atol=0.001))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(np.isclose(min_wrist_torque_successful_z, -0.293665094, atol=0.001))\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "channel_index": {
     "name": "channel_index",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert(index_wrist_torque_offset == 3)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "count_rows": {
     "name": "count_rows",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert(pick_data.shape[0] == 660)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(n_picks == 660)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(n_successful == 355)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "hours_collaborators": {
     "name": "hours_collaborators",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert(not \"not filled out\" in worked_with_names)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(not \"not filled out\" in websites)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(hours > 0)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "number_dimensions": {
     "name": "number_dimensions",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert(pick_channel_data.shape[0] == pick_data.shape[0])\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(pick_successful.size == pick_data.shape[0])\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(pick_channel_data.shape[1] == n_time_steps * n_total_dims)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(n_total_dims == 33)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(n_time_steps == 40)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "read_json": {
     "name": "read_json",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert(len(data_channels) == len(pick_data_description[\"Data channels\"]))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(len(data_channels) == 17)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "slicing": {
     "name": "slicing",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert(wrist_torque_data.shape[0] == pick_data.shape[0])\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(wrist_torque_data.shape[1] == 3 * 40)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(np.isclose(wrist_torque_data[0, 0], -0.268183058, atol=0.001))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(np.isclose(wrist_torque_data[0, -1], -0.-0.077284199, atol=0.001))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(np.isclose(wrist_torque_data[-1, 0], -0.346147999, atol=0.001))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(np.isclose(wrist_torque_data[-1, -1], -0.048521821, atol=0.001))\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "statistics": {
     "name": "statistics",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> from check_json_answers import compare_files\n>>> assert(compare_files(wrist_torque_stats_list, \"Lab1_check_results.json\"))\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
